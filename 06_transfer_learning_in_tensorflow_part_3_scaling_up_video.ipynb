{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_transfer_learning_in_tensorflow_part_3_scaling_up_video.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvh2Oj2KMPQZIeuxOggdso",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vortexash/Tensorflow-Developer/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with Tensorflow Part 3: Scaling up (Food Vision mini)\n",
        "\n",
        "We've seen the power of transfer Learning feature extraction and fine-tuning, now it;s time to scale up to all the classes in Food101 (101 total classes of food)\n",
        "\n",
        "Our goal is to beat the original Food101 papre with 10% of the training data (leveraging the power of Deep Learning)\n",
        "\n",
        "Original Food101 paper: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf\n",
        "\n",
        "Our basekine to beat is 50.76% across 101 classes.\n"
      ],
      "metadata": {
        "id": "_7gjoaHE1O_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if we're using a GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_6sgCm46hJ6",
        "outputId": "377d62e3-99ec-4d6f-bf37-dc05d0d3c180"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 16 17:26:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "In previous notebooks, we've created a series of healper functions to do different tasks, let's download them."
      ],
      "metadata": {
        "id": "K81mneTG7NM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vortexash/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_IodBEt7ywn",
        "outputId": "fd65e1da-1586-4264-ffc3-d9edae81e087"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-16 17:28:48--  https://raw.githubusercontent.com/vortexash/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-16 17:28:48 (60.0 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for our notebook.\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir, compare_historys"
      ],
      "metadata": {
        "id": "X4GQB6hH7rp2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 101 Food  Classes: woring with less data\n",
        "\n",
        "Our goal is to beat the original Food101 paper with 10% of the training data, so Let's download it.\n",
        "\n",
        "The data we're downloading comes from the original Food101  data set but has been preprocessed using image modification notebook.\n"
      ],
      "metadata": {
        "id": "IrWPsgeI8Atf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OsT69sX8xOX",
        "outputId": "35977f3d-7ad4-4290-9ed8-01458da19805"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-16 17:33:53--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.5.128, 64.233.184.128, 64.233.166.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.5.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   103MB/s    in 16s     \n",
            "\n",
            "2022-01-16 17:34:10 (97.8 MB/s) - ‘101_food_classes_10_percent.zip’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "train_dir = \"/content/101_food_classes_10_percent/train\"\n",
        "test_dir = \"/content/101_food_classes_10_percent/test\""
      ],
      "metadata": {
        "id": "sGuSiARw8-As"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images/classes are there?\n",
        "walk_through_dir(\"101_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "4jLIfdlL9Sn7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "import tensorflow as tf\n",
        "IMG_SIZE =(224,224)\n",
        "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                           label_mode=\"categorical\",\n",
        "                                                                           image_size=IMG_SIZE)\n",
        "test_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                           label_mode=\"categorical\",\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                          shuffle=False) # don't shuffle test data fro prediction analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "R11KTeiR9hEC",
        "outputId": "fa0bcf54-4930-4122-af87-95cf66325a91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-346e65810bb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n\u001b[1;32m      5\u001b[0m                                                                            \u001b[0mlabel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                                            image_size=IMG_SIZE)\n\u001b[0m\u001b[1;32m      7\u001b[0m test_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n\u001b[1;32m      8\u001b[0m                                                                            \u001b[0mlabel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m       \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       follow_links=follow_links)\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0msubdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '101_food_classes_10_percent.zip/train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ByEuLDp-dSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}